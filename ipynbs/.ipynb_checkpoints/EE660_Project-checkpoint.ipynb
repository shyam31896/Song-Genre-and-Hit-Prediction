{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset_constructor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset creation  -  Genre Prediction Dataset ###\n",
    "\n",
    "''' \n",
    "\n",
    "To create the dataset for this project, a custom code is written to extract audio from Youtube using the tool `youtube-dl` \n",
    "and data collected for the 7 specific music genres from the `AudioSet` released by Google.\n",
    "\n",
    "source: https://arxiv.org/pdf/1804.01149.pdf\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import re\n",
    "import youtube_dl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from audio_utils import pre_emphasis, MFCC, Zero_crossing_rate, Spectral_centroid, Spectral_rolloff, Chroma_feat\n",
    "\n",
    "WAV_DIR = 'wav_files/'\n",
    "genre_dict = {'/m/064t9': 'Pop_music',\n",
    "\t\t     '/m/0glt670': 'Hip_hop_music',\n",
    "                     '/m/06by7': 'Rock_music',\n",
    "                     '/m/06j6l': 'Rhythm_blues',\n",
    "                     '/m/06cqb': 'Reggae', \n",
    "                     '/m/0y4f8': 'Vocal',\n",
    "                     '/m/07gxw': 'Techno'}\n",
    "\n",
    "genre_set = set(genre_dict.keys())\n",
    "temp_str = []\n",
    "os.system('tar -xvf data-info.tar.gz | grep data-files')\n",
    "with open('data-files/unbalanced_train_segments.csv', 'r') as f:\n",
    "    temp_str = f.readlines()\n",
    "data = np.ones(shape=(1,4)) \n",
    "\n",
    "print('Downloading audio files:')\n",
    "\n",
    "for line in tqdm(temp_str):\n",
    "    line = re.sub('\\s?\"', '', line.strip())\n",
    "    elements = line.split(',')\n",
    "    common_elements = list(genre_set.intersection(elements[3:]))\n",
    "    if  common_elements != []:\n",
    "        data = np.vstack([data, np.array(elements[:3] + [genre_dict[common_elements[0]]]).reshape(1, 4)])\n",
    "\n",
    "df = pd.DataFrame(data[1:], columns=['url', 'start_time', 'end_time', 'class_label'])\n",
    "\n",
    "# Remove 10k Techno audio clips - to make the data more balanced\n",
    "\n",
    "np.random.seed(10)\n",
    "drop_indices = np.random.choice(df[df['class_label'] == 'Techno'].index, size=10000, replace=False)\n",
    "df.drop(labels=drop_indices, axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=False)\n",
    "df['start_time'] = df['start_time'].map(lambda x: np.int32(np.float(x)))\n",
    "df['end_time'] = df['end_time'].map(lambda x: np.int32(np.float(x)))\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    url = \"'https://www.youtube.com/embed/\" + row['url'] + \"'\"\n",
    "    file_name = str(i)+\"_\"+row['class_label']\n",
    "    try:\n",
    "        command_1 = \"ffmpeg -ss \"+str(row['start_time'])+\" -i $(youtube-dl -f 140 --get-url \"+url+\") -t 10 -c:v copy -c:a copy \"+file_name+\".mp4\"\n",
    "        command_2 = \"ffmpeg -i \"+file_name+\".mp4 -vn -acodec pcm_s16le -ar 44100 -ac 1 \"+WAV_DIR+file_name+\".wav\"\n",
    "        command_3 = 'rm '+file_name+'.mp4' \n",
    "        os.system(command_1 + ';' + command_2 + ';' + command_3 + ';')\n",
    "    except:\n",
    "        print(i, url)\n",
    "        pass\n",
    "\n",
    "print('Download complete')\n",
    "### Feature extraction and building dataset from downloaded audio files ###\n",
    "\n",
    "cols = ['file_name'] + ['signal_mean'] + ['signal_std'] +\\\n",
    "       ['mfcc_' + str(i+1) + '_mean' for i in range(20)] + ['mfcc_' + str(i+1) + '_std' for i in range(20)] + \\\n",
    "       ['zero_crossing_mean','zero_crossing_std','spec_centroid_mean','spec_centroid_std', \\\n",
    "        'spec_rolloff_mean','spec_rolloff_std'] + \\\n",
    "       ['chroma_' + str(i+1) + '_mean' for i in range(12)] + ['chroma_' + str(i+1) + '_std' for i in range(12)] +\\\n",
    "       ['label']\n",
    "labels = {'Hip':0,'Pop':1,'Vocal':2,'Rhythm':3,'Reggae':4,'Rock':5,'Techno':6}\n",
    "\n",
    "print('Feature extraction started')\n",
    "dataset = pd.DataFrame(columns=cols)\n",
    "for file in tqdm(os.listdir('wav_files')):\n",
    "    signal, sample_rate = librosa.load('wav_files/'+file, sr = 22050)\n",
    "    pre_emphasized_signal = pre_emphasis(signal)\n",
    "    signal_mean = np.mean(abs(pre_emphasized_signal))\n",
    "    signal_std = np.std(pre_emphasized_signal)\n",
    "    mel_scaled_out = MFCC(pre_emphasized_signal)\n",
    "    zero_crossing = Zero_crossing_rate(pre_emphasized_signal)\n",
    "    spec_centroid = Spectral_centroid(pre_emphasized_signal)\n",
    "    spec_rolloff = Spectral_rolloff(pre_emphasized_signal)\n",
    "    chroma = Chroma_feat(pre_emphasized_signal)\n",
    "    res_list = []\n",
    "    res_list.append(file)\n",
    "    res_list.append(signal_mean)\n",
    "    res_list.append(signal_std)\n",
    "    res_list.extend(np.mean(mel_scaled_out, axis = 1))\n",
    "    res_list.extend(np.std(mel_scaled_out, axis = 1))\n",
    "    res_list.extend((np.mean(zero_crossing), np.std(zero_crossing), np.mean(spec_centroid), np.std(spec_centroid)))\n",
    "    res_list.extend((np.mean(spec_rolloff), np.std(spec_rolloff)))\n",
    "    res_list.extend(np.mean(chroma, axis = 1))\n",
    "    res_list.extend(np.std(chroma, axis = 1))\n",
    "    res_list.extend(str(labels.get(file.replace('.','_').split('_')[1])))\n",
    "    dataset = dataset.append(pd.DataFrame(res_list, index = cols).T, ignore_index = True)\n",
    "dataset.to_csv(\"dataset_genre_pred.csv\", index = False)\n",
    "\n",
    "dataset_genre = pd.read_csv('dataset_genre_pred.csv')\n",
    "dataset_genre['label'] = pd.to_numeric(dataset_genre['label'])\n",
    "data_train_genre, data_sec_genre = train_test_split(dataset_genre.drop('file_name', axis = 1), test_size = 0.2, random_state=5)\n",
    "data_val_genre, data_test_genre = train_test_split(data_sec_genre, test_size = 0.4, random_state=5)\n",
    "scaler = MinMaxScaler()\n",
    "data_train_genre[data_train_genre.columns[1:len(data_train_genre.columns)-1]] = scaler.fit_transform(data_train_genre[data_train_genre.columns[1:len(data_train_genre.columns)-1]])\n",
    "data_val_genre[data_val_genre.columns[1:len(data_val_genre.columns)-1]] = scaler.transform(data_val_genre[data_val_genre.columns[1:len(data_val_genre.columns)-1]])\n",
    "data_test_genre[data_test_genre.columns[1:len(data_test_genre.columns)-1]] = scaler.transform(data_test_genre[data_test_genre.columns[1:len(data_test_genre.columns)-1]])\n",
    "os.system('rm -rf data/')\n",
    "os.system('mkdir data/')\n",
    "data_train_genre.to_csv('data/data_genre_training.csv', index = False)\n",
    "data_val_genre.to_csv('data/data_genre_validation.csv', index = False)\n",
    "data_test_genre.to_csv('data/data_genre_test.csv', index = False)\n",
    "print('Genre Dataset successfully constructed')\n",
    "\n",
    "####### Construct dataset for Song Hit Prediction #######\n",
    "\n",
    "import billboard\n",
    "import datetime \n",
    "import time\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### Collect Songs from Billboard for the given time range of 20 years ###\n",
    "\n",
    "'''\n",
    "\n",
    "To collect songs from using the Billboard API, query data for a maximum duration of two years as the API stops responding \n",
    "if the number of requests made by the function is too large\n",
    "\n",
    "'''\n",
    "print('Billboard audio extraction starts')\n",
    "num_years = 2\n",
    "for year in [\"%.2d\" % i for i in range(19-num_years+1, 19)]:\n",
    "    prev_date_list = []\n",
    "    date1 = '20'+year+'-01-01'\n",
    "    date2 = '20'+str(int(year)+1)+'-11-30'\n",
    "    start = datetime.datetime.strptime(date1, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(date2, '%Y-%m-%d')\n",
    "    step = datetime.timedelta(days=60)\n",
    "    while start <= end:\n",
    "        prev_date_list.append(str(start.date()))\n",
    "        start += step\n",
    "    print(prev_date_list)\n",
    "\n",
    "    cols = ['Artist','Track','Label']\n",
    "    billboard_df = pd.DataFrame()\n",
    "    chart = billboard.ChartData('hot-100', prev_date_list[0])\n",
    "    for i in range(1, len(prev_date_list)):\n",
    "        for ind in range(1, len(chart))[:30]:\n",
    "            song = chart[ind]\n",
    "            if i != 1 and song.title in billboard_df[1]:\n",
    "                pass\n",
    "            else:\n",
    "                entry = []\n",
    "                entry.extend((song.artist, song.title, str(1)))\n",
    "                billboard_df = billboard_df.append(pd.DataFrame(entry).T)\n",
    "        chart = billboard.ChartData('hot-100', prev_date_list[i])\n",
    "        time.sleep(1)\n",
    "billboard_df.to_csv(\"billboard_data.csv\", index=False)\n",
    "print('Billboard audio extraction complete')\n",
    "### Collect Songs which did not make it to the Billboard for the given time range of 20 years ###\n",
    "\n",
    "print('Non-Billboard audio extraction starts')\n",
    "billboard_df = pd.read_csv(\"billboard_data.csv\", names=cols).iloc[1:,:]\n",
    "chart = billboard.ChartData('radio-songs', prev_date_list[0])\n",
    "for i in range(1, len(prev_date_list)):\n",
    "    for ind in range(1, len(chart))[:30]:\n",
    "        song = chart[ind]\n",
    "        if i != 1 and song.title in billboard_df.iloc[:,1]:\n",
    "            pass\n",
    "        else:\n",
    "            entry = []\n",
    "            entry.extend((song.artist, song.title, str(0)))\n",
    "            billboard_df = billboard_df.append(pd.DataFrame(entry, index=cols).T)\n",
    "    chart = billboard.ChartData('radio-songs', prev_date_list[i])\n",
    "    time.sleep(2)\n",
    "billboard_df.to_csv(\"billboard_data.csv\", index=False)\n",
    "print('Non-Billboard audio extraction complete')\n",
    "\n",
    "### Extract Song features from Spotify and construct the dataset ###\n",
    "\n",
    "billboard_df = pd.read_csv(\"billboard_data.csv\")\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=\"769ef3519e8444238fde9c8981c6371c\",\\\n",
    "                                                      client_secret=\"b17e4a7ca0b4426f9962645ba5c74a63\")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "features_df = pd.DataFrame()\n",
    "time_df = pd.DataFrame()\n",
    "release_feat = ['Year','Month']\n",
    "spotify_feat = ['Danceability','Energy','Key','Loudness','Mode','Speechiness','Acousticness','Instrumentalness','Liveness','Valence','Tempo']\n",
    "\n",
    "for ind in range(len(billboard_df.iloc[:,0:2])):\n",
    "    artist, track = billboard_df.iloc[ind,0:2]\n",
    "    songs=sp.search(q='track:'+track+' '+'artist:'+artist+'*' , type='track')\n",
    "    items = songs['tracks']['items']\n",
    "    features_to_df = []\n",
    "\n",
    "    if len(items) == 0:\n",
    "        features_df = features_df.append(pd.Series(['None']*18), ignore_index = True)\n",
    "        time_df = time_df.append(pd.Series(['None']*2), ignore_index = True)\n",
    "\n",
    "    else:\n",
    "        track = items[0]\n",
    "        song_id = str(track[\"id\"])\n",
    "        track_features=sp.audio_features(song_id)\n",
    "        if int(track['album']['release_date'].split('-')[0]) < 2000: \n",
    "            y = 'None'\n",
    "            m = 'None'\n",
    "        else:\n",
    "            y = track['album']['release_date'].split('-')[0]\n",
    "            m = track['album']['release_date'].split('-')[1]\n",
    "        rel = [y,m]\n",
    "        time_df = time_df.append(pd.DataFrame(rel).T)\n",
    "        features_to_df = [val for val in (track_features)[0].values()]\n",
    "        features_df = features_df.append(pd.DataFrame(features_to_df).T)\n",
    "\n",
    "features_df = features_df.drop([11, 12, 13, 14, 15, 16, 17], axis=1)\n",
    "features_df.columns = spotify_feat\n",
    "time_df.columns = release_feat\n",
    "output = pd.concat([billboard_df.iloc[:-1,:],features_df.iloc[:-1,:],time_df.iloc[:-1,:]],axis=1)\n",
    "output.to_csv(\"billboard_data_with_spotify.csv\", index = False)\n",
    "dataset = pd.read_csv('billboard_data_with_spotify.csv').drop(['Artist','Track'], axis = 1)\n",
    "colnames = list(dataset.columns)\n",
    "dataset_no_label = dataset.drop(['Label'], axis = 1)\n",
    "dataset['Label'] = pd.to_numeric(dataset['Label'])\n",
    "data_train, data_sec = train_test_split(dataset, test_size = 0.1, random_state=5)\n",
    "data_val, data_test = train_test_split(data_sec, test_size = 0.5, random_state=5)\n",
    "scaler = MinMaxScaler()\n",
    "data_train[data_train.columns[:2]] = scaler.fit_transform(data_train[data_train.columns[:2]])\n",
    "data_val[data_val.columns[:2]] = scaler.transform(data_val[data_val.columns[:2]])\n",
    "data_test[data_test.columns[:2]] = scaler.transform(data_test[data_test.columns[:2]])\n",
    "data_train[data_train.columns[3:4]] = scaler.fit_transform(data_train[data_train.columns[3:4]])\n",
    "data_val[data_val.columns[3:4]] = scaler.transform(data_val[data_val.columns[3:4]])\n",
    "data_test[data_test.columns[3:4]] = scaler.transform(data_test[data_test.columns[3:4]])\n",
    "data_train[data_train.columns[5:len(data_train.columns)-3]] = scaler.fit_transform(data_train[data_train.columns[5:len(data_train.columns)-3]])\n",
    "data_val[data_val.columns[5:len(data_val.columns)-3]] = scaler.transform(data_val[data_val.columns[5:len(data_val.columns)-3]])\n",
    "data_test[data_test.columns[5:len(data_test.columns)-3]] = scaler.transform(data_test[data_test.columns[5:len(data_test.columns)-3]])\n",
    "data_train.to_csv('data/data_hit_training.csv', index = False)\n",
    "data_val.to_csv('data/data_hit_validation.csv', index = False)\n",
    "data_test.to_csv('data/data_hit_test.csv', index = False)\n",
    "\n",
    "### Visualizing the Datapoints - Hit Predictor ###\n",
    "\n",
    "color = []\n",
    "for i in dataset['Label']:\n",
    "    if i == 1:\n",
    "        color.append('blue')\n",
    "    else:\n",
    "        color.append('red')\n",
    "# Used Pandas to plot the scatter plot of the independent variables\n",
    "pd.plotting.scatter_matrix(dataset_no_label,figsize=(15,15),marker='.',c=color,alpha=0.5,s=50)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.suptitle('Fig.1: Scatterplot of Independent Variables', fontsize=16)\n",
    "# Extra commands to display legend\n",
    "c0, = plt.plot([1,1],'r.')\n",
    "c1, = plt.plot([1,1],'b.')\n",
    "plt.legend((c0, c1),('Normal Song', 'Hit Song'),loc=(-0.5,13.1))\n",
    "c0.set_visible(False)\n",
    "c1.set_visible(False)\n",
    "plt.savefig('results/conf_matrices/hit_pred_scatter_matrix.jpg')\n",
    "\n",
    "print('Audio features extracted and Hit Prediction Dataset Construction complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from librosa import display\n",
    "\n",
    "'''\n",
    "\n",
    "Perform Pre-emphasis\n",
    "\n",
    "source: https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "\n",
    "'''\n",
    "\n",
    "def pre_emphasis(signal, pre_emphasis_coeff = 0.95):  # most commonly used values are 0.95 and 0.97\n",
    "    pre_emphasis_coeff = pre_emphasis_coeff\n",
    "    emphasized_signal = np.append(signal[0], signal[1:] - pre_emphasis_coeff * signal[:-1])\n",
    "    return emphasized_signal\n",
    "\n",
    "def MFCC(emphasized_signal):\n",
    "    mel = librosa.feature.mfcc(emphasized_signal)\n",
    "    mel_scaled = scale(mel, axis = 1)\n",
    "    return mel_scaled\n",
    "\n",
    "def Zero_crossing_rate(emphasized_signal, eps = 0.001):     # To prevent silence being mistaken as noise\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(emphasized_signal + eps)\n",
    "    zero_crossing = zero_crossing[0]\n",
    "    return zero_crossing\n",
    "\n",
    "def Spectral_centroid(emphasized_signal, eps = 0.001):\n",
    "    spec_centroid = librosa.feature.spectral_centroid(emphasized_signal + eps)\n",
    "    spec_centroid = spec_centroid[0]\n",
    "    return spec_centroid\n",
    "\n",
    "def Spectral_rolloff(emphasized_signal, eps = 0.001):\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(emphasized_signal + eps)\n",
    "    spec_rolloff = spec_rolloff[0]\n",
    "    return spec_rolloff\n",
    "\n",
    "def Chroma_feat(emphasized_signal):\n",
    "    chroma = librosa.feature.chroma_stft(emphasized_signal, hop_length=1024)\n",
    "    return chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sn\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#Pre-processing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n",
    "\n",
    "# Splitting Data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import xgboost as xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Save / Load models\n",
    "import joblib\n",
    "\n",
    "os.system('rm -rf models/')\n",
    "os.system('mkdir models/')\n",
    "\n",
    "### Load and Preprocess the data for Genre Prediction ###\n",
    "\n",
    "labels = {'Hip':0,'Pop':1,'Vocal':2,'Rhythm':3,'Reggae':4,'Rock':5,'Techno':6}\n",
    "data_train_genre = pd.read_csv('data/data_genre_training.csv')\n",
    "ytrain_genre, xtrain_genre = data_train_genre['label'], data_train_genre[data_train_genre.columns[:len(data_train_genre.columns)-1]]\n",
    "print('Loaded Genre Dataset!')\n",
    "\n",
    "### Naive Bayes Classifier - Genre ###\n",
    "\n",
    "naive = GaussianNB().fit(xtrain_genre, ytrain_genre)\n",
    "joblib.dump(naive,'models/naive_bayes_genre_trained.pkl')\n",
    "\n",
    "### Logistic Regression Classifier - Genre ###\n",
    "\n",
    "logregcv = LogisticRegressionCV(cv=10, multi_class='multinomial').fit(xtrain_genre, ytrain_genre)\n",
    "joblib.dump(logregcv,'models/logreg_genre_trained.pkl')\n",
    "\n",
    "### Support Vector Machine Classifier - Genre ###\n",
    "\n",
    "C_est = range(100, 1001, 100)\n",
    "acc_test = []\n",
    "for i in C_est:\n",
    "    svc = SVC(C = i, probability = True, class_weight=dict(ytrain_genre.value_counts(normalize = True)))\n",
    "    svc.fit(xtrain_genre, ytrain_genre)\n",
    "    svm_pred_test = svc.predict(xval_genre)\n",
    "    acc_test.append(accuracy_score(yval_genre,svm_pred_test))\n",
    "C_est_opt = 50 * acc_test.index(np.max(acc_test))\n",
    "\n",
    "svc = SVC(C = C_est_opt, probability = True, class_weight=dict(ytrain_genre.value_counts(normalize = True)))\n",
    "svc.fit(xtrain_genre, ytrain_genre)\n",
    "joblib.dump(svc,'models/svm_genre_trained.pkl')\n",
    "\n",
    "### Random Forest Classifier - Genre ###\n",
    "\n",
    "N_est = range(100, 1001, 100)\n",
    "acc_test = []\n",
    "for i in N_est:\n",
    "    rf = RandomForestClassifier(n_estimators=i, min_samples_split=10)\n",
    "    rf.fit(xtrain_genre,ytrain_genre)\n",
    "    rf_pred_test = rf.predict(xval_genre)\n",
    "    acc_test.append(accuracy_score(yval_genre,rf_pred_test))\n",
    "N_est_opt = 100 * acc_test.index(np.max(acc_test))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=N_est_opt, min_samples_split=10)\n",
    "rf.fit(xtrain_genre, ytrain_genre)\n",
    "joblib.dump(rf,'models/random_forest_genre_trained.pkl')\n",
    "\n",
    "### Gradient Boosting Tree Classifier - Genre ###\n",
    "\n",
    "N_est = range(100, 1001, 100)\n",
    "acc_test = []\n",
    "for i in N_est:\n",
    "    boost = XGBClassifier(n_estimators=i, max_depth=10, subsample=0.8, num_class = len(labels), objective='multi:softprob')\n",
    "    boost.fit(xtrain_genre, ytrain_genre)\n",
    "    boost_pred_test = boost.predict(xval_genre)\n",
    "    acc_test.append(accuracy_score(yval_genre,boost_pred_test))\n",
    "N_est_opt = 100 * acc_test.index(np.max(acc_test))\n",
    "\n",
    "boost = XGBClassifier(n_estimators=N_est_opt, max_depth=5, subsample=0.8, num_class = len(labels), objective='multi:softprob')\n",
    "boost.fit(xtrain_genre, ytrain_genre)\n",
    "joblib.dump(boost,'models/xgboost_genre_trained.pkl')\n",
    "\n",
    "print('Training models for Genre Prediction Complete!')\n",
    "\n",
    "### Load and Preprocess the data for Hit Prediction ###\n",
    "\n",
    "data_train = pd.read_csv('data/data_hit_training.csv')\n",
    "ytrain, xtrain = data_train['Label'], data_train.iloc[:,:-1]\n",
    "print('Loaded Billboard Hits Dataset!')\n",
    "\n",
    "### K Nearest Neighbors Classifier - Hit Predictor ###\n",
    "\n",
    "err_test = []\n",
    "step_k = 1\n",
    "k = range(1, 50, step_k)\n",
    "for i in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,p=2)        \n",
    "    knn.fit(xtrain, ytrain)            \n",
    "    predict_train = knn.predict(xtrain)       \n",
    "    predict_test = knn.predict(xval)         \n",
    "    err_test.append(np.mean(predict_test != yval))     \n",
    "\n",
    "k_opt = 1 + step_k * err_test.index(np.min(err_test))    \n",
    "print('Optimal K for Test data using Manhattan distance metric is', k_opt)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = k_opt, p = 1)   \n",
    "knn.fit(xtrain, ytrain)\n",
    "joblib.dump(knn,'models/knn_hit_trained.pkl')\n",
    "\n",
    "### Logistic Regression Classifier - Hit Predictor ###\n",
    "\n",
    "lreg = LogisticRegressionCV(cv = 10, solver = 'liblinear', penalty = 'l1',refit=True)\n",
    "lreg.fit(xtrain,ytrain)\n",
    "joblib.dump(lreg, 'models/logreg_hit_trained.pkl')\n",
    "\n",
    "### Support Vector Machine Classifier - Hit Predictor ###\n",
    "\n",
    "C_est = range(1, 101, 5)\n",
    "acc_test = []\n",
    "for i in C_est:\n",
    "    svc = SVC(C = i, probability = True, class_weight=dict(ytrain.value_counts(normalize = True)))\n",
    "    svc.fit(xtrain, ytrain)\n",
    "    svc_pred_test = svc.predict(xval)\n",
    "    acc_test.append(accuracy_score(yval,svc_pred_test))\n",
    "C_est_opt = 5 * acc_test.index(np.max(acc_test))\n",
    "\n",
    "svc = SVC(C = C_est_opt, probability = True, class_weight=dict(ytrain.value_counts(normalize = True)))\n",
    "svc.fit(xtrain, ytrain)\n",
    "joblib.dump(svc,'models/svm_hit_trained.pkl')\n",
    "\n",
    "### Random Forest Classifier - Hit Predictor ###\n",
    "\n",
    "N_est = range(100, 1001, 25)\n",
    "acc_test = []\n",
    "for i in N_est:\n",
    "    rf = RandomForestClassifier(n_estimators=i, min_samples_split=10)\n",
    "    rf.fit(xtrain,ytrain)\n",
    "    rf_pred_test = rf.predict(xval)\n",
    "    acc_test.append(accuracy_score(yval,rf_pred_test))\n",
    "N_est_opt = 100 * acc_test.index(np.max(acc_test))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=N_est_opt, min_samples_split=10)\n",
    "rf.fit(xtrain, ytrain)\n",
    "joblib.dump(rf, 'models/random_forest_hit_trained.pkl')\n",
    "\n",
    "### Gradient Boosting Trees - Hit Predictor ###\n",
    "\n",
    "N_est = range(100, 1001, 100)\n",
    "acc_test = []\n",
    "for i in N_est:\n",
    "    boost = XGBClassifier(n_estimators=i, max_depth=10, subsample=0.9, num_class = 2, objective='multi:softmax')\n",
    "    boost.fit(xtrain, ytrain)\n",
    "    boost_pred_test = boost.predict(xval)\n",
    "    acc_test.append(accuracy_score(yval,boost_pred_test))\n",
    "N_est_opt = 100 * (acc_test.index(np.max(acc_test))-1)\n",
    "\n",
    "boost = XGBClassifier(n_estimators=N_est_opt, max_depth=10, subsample=0.9, num_class = 2, objective='multi:softmax')\n",
    "boost.fit(xtrain, ytrain)\n",
    "joblib.dump(boost, 'models/xgboost_hit_trained.pkl')\n",
    "\n",
    "print('Training models for Hit Prediction Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sn\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Save / Load models\n",
    "import joblib\n",
    "\n",
    "### Load the data for Validating the predicted Genre ###\n",
    "\n",
    "labels = {'Hip':0,'Pop':1,'Vocal':2,'Rhythm':3,'Reggae':4,'Rock':5,'Techno':6}\n",
    "data_val_genre = pd.read_csv('data/data_genre_validation.csv')\n",
    "yval_genre, xval_genre = data_val_genre['label'], data_val_genre[data_val_genre.columns[:len(data_val_genre.columns)-1]]\n",
    "os.system('rm -rf results/')\n",
    "os.system('mkdir results/')\n",
    "os.system('rm -rf results/conf_matrices/')\n",
    "os.system('mkdir results/conf_matrices/')\n",
    "\n",
    "### Naive Bayes Classifier - Genre ###\n",
    "\n",
    "naive = joblib.load('models/naive_bayes_genre_trained.pkl')\n",
    "naive_pred = naive.predict(xval_genre)\n",
    "mat = confusion_matrix(yval_genre, naive_pred)\n",
    "temp = pd.DataFrame(mat, index=list(labels.keys()), columns=list(labels.keys()))\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Naive Bayes Model Genre: Confusion matrix')\n",
    "fig.savefig('results/conf_matrices/genre_naive_bayes_cm.jpg')\n",
    "\n",
    "### Logistic Regression Classifier - Genre ###\n",
    "\n",
    "logregcv = joblib.load('models/logreg_genre_trained.pkl')\n",
    "logreg_pred = logregcv.predict(xval_genre)\n",
    "mat = confusion_matrix(yval_genre, logreg_pred)\n",
    "temp = pd.DataFrame(mat, index=list(labels.keys()), columns=list(labels.keys()))\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Logistic Regression Model Genre: Confusion matrix')\n",
    "fig.savefig('results/conf_matrices/genre_logreg_cm.jpg')\n",
    "\n",
    "### Support Vector Machine Classifier - Genre ###\n",
    "\n",
    "svc = joblib.load('models/svm_genre_trained.pkl')\n",
    "svm_pred = svc.predict(xval_genre)\n",
    "mat = confusion_matrix(yval_genre, svm_pred)\n",
    "temp = pd.DataFrame(mat, index=list(labels.keys()), columns=list(labels.keys()))\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('SVM Model Genre: Confusion matrix')\n",
    "fig.savefig('results/conf_matrices/genre_svm_cm.jpg')\n",
    "\n",
    "### Random Forest Classifier - Genre ###\n",
    "\n",
    "rf = joblib.load('models/random_forest_genre_trained.pkl')\n",
    "rf_pred = rf.predict(xval_genre)\n",
    "mat = confusion_matrix(yval_genre, rf_pred)\n",
    "temp = pd.DataFrame(mat, index=list(labels.keys()), columns=list(labels.keys()))\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Random Forest Model Genre: Confusion matrix')\n",
    "fig.savefig('results/conf_matrices/genre_random_forest_cm.jpg')\n",
    "\n",
    "### Gradient Boosting Tree Classifier - Genre ###\n",
    "\n",
    "boost = joblib.load('models/xgboost_genre_trained.pkl')\n",
    "boost_pred = boost.predict(xval_genre)\n",
    "mat = confusion_matrix(yval_genre, boost_pred)\n",
    "temp = pd.DataFrame(mat, index=list(labels.keys()), columns=list(labels.keys()))\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Gradient Boosted Tree Model Genre: Confusion matrix')\n",
    "fig.savefig('results/conf_matrices/genre_xgboost_cm.jpg')\n",
    "\n",
    "model_accuracy = []\n",
    "model_accuracy.append(round(accuracy_score(yval_genre,naive_pred),3))\n",
    "model_accuracy.append(round(accuracy_score(yval_genre,logreg_pred),3))\n",
    "model_accuracy.append(round(accuracy_score(yval_genre,svm_pred),3))\n",
    "model_accuracy.append(round(accuracy_score(yval_genre,rf_pred),3))\n",
    "model_accuracy.append(round(accuracy_score(yval_genre,boost_pred),3))\n",
    "\n",
    "model_fscore = []\n",
    "model_fscore.append(round(f1_score(yval_genre,naive_pred,average='weighted'),3))\n",
    "model_fscore.append(round(f1_score(yval_genre,logreg_pred,average = 'weighted'),3))\n",
    "model_fscore.append(round(f1_score(yval_genre,svm_pred,average = 'weighted'),3))\n",
    "model_fscore.append(round(f1_score(yval_genre,rf_pred,average = 'weighted'),3))\n",
    "model_fscore.append(round(f1_score(yval_genre,boost_pred,average = 'weighted'),3))\n",
    "\n",
    "res_list_genre = []\n",
    "res_list_genre.append(model_accuracy)\n",
    "res_list_genre.append(model_fscore)\n",
    "\n",
    "eval_metrics_genre = ['Accuracy','F-Score']\n",
    "models_to_test_genre = ['Naive Bayes','Logistic Regression','Support Vector Machine','Random Forest','XGBoost']\n",
    "metrics_genre = pd.DataFrame(res_list_genre, columns=models_to_test_genre, index=eval_metrics_genre)\n",
    "metrics_genre.index.name = 'Metric'\n",
    "metrics_genre.to_csv('results/eval_metrics_training.csv')\n",
    "\n",
    "### Load the data for validating Hit Prediction ###\n",
    "\n",
    "data_val = pd.read_csv('data/data_hit_validation.csv')\n",
    "yval, xval = data_val['Label'], data_val.iloc[:,:-1]\n",
    "\n",
    "### K Nearest Neighbors Classifier - Hit Predictor ###\n",
    "\n",
    "knn = joblib.load('models/knn_hit_trained.pkl')\n",
    "predict_test = knn.predict(xval)\n",
    "predict_test = predict_test[:,np.newaxis]\n",
    "mat = confusion_matrix(yval, predict_test)\n",
    "temp = pd.DataFrame(mat, index=['Hit Song','Normal'], columns=['Hit Song','Normal'])\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "fig.savefig('results/conf_matrices/hit_knn_cm.jpg')\n",
    "\n",
    "### Logistic Regression Classifier - Hit Predictor ###\n",
    "\n",
    "lreg = joblib.load('models/logreg_hit_trained.pkl')\n",
    "pred_lreg = lreg.predict(xval)\n",
    "mat = confusion_matrix(yval, pred_lreg)\n",
    "temp = pd.DataFrame(mat, index=['Hit Song','Normal'], columns=['Hit Song','Normal'])\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "fig.savefig('results/conf_matrices/hit_logreg_cm.jpg')\n",
    "\n",
    "### Support Vector Machine Classifier - Hit Predictor ###\n",
    "\n",
    "svc = joblib.load('models/svm_hit_trained.pkl')\n",
    "svm_pred = svc.predict(xval)\n",
    "mat = confusion_matrix(yval, svm_pred)\n",
    "temp = pd.DataFrame(mat, index=['Hit Song','Normal'], columns=['Hit Song','Normal'])\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "fig.savefig('results/conf_matrices/hit_svm_cm.jpg')\n",
    "\n",
    "### Random Forest Classifier - Hit Predictor ###\n",
    "\n",
    "rf = joblib.load('models/random_forest_hit_trained.pkl')\n",
    "rf_pred = rf.predict(xval) \n",
    "mat = confusion_matrix(yval, rf_pred)\n",
    "temp = pd.DataFrame(mat, index=['Hit Song','Normal'], columns=['Hit Song','Normal'])\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "fig.savefig('results/conf_matrices/hit_random_forest_cm.jpg')\n",
    "\n",
    "### Gradient Boosting Trees - Hit Predictor ###\n",
    "\n",
    "boost = joblib.load('models/xgboost_hit_trained.pkl')\n",
    "boost_pred = boost.predict(xval)\n",
    "mat = confusion_matrix(yval, boost_pred)\n",
    "temp = pd.DataFrame(mat, index=['Hit Song','Normal'], columns=['Hit Song','Normal'])\n",
    "fig = plt.figure()\n",
    "sn.heatmap(temp, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "fig.savefig('results/conf_matrices/hit_xgboost_cm.jpg')\n",
    "\n",
    "\n",
    "model_accuracy = []\n",
    "model_accuracy.append(round(accuracy_score(yval,predict_test),3))\n",
    "model_accuracy.append(round(accuracy_score(yval,pred_lreg),3))\n",
    "model_accuracy.append(round(accuracy_score(yval,svm_pred),3))\n",
    "model_accuracy.append(round(accuracy_score(yval,rf_pred),3))\n",
    "model_accuracy.append(round(accuracy_score(yval,boost_pred),3))\n",
    "\n",
    "model_fscore = []\n",
    "model_fscore.append(round(f1_score(yval,predict_test,average = None)[1],3))\n",
    "model_fscore.append(round(f1_score(yval,pred_lreg,average = None)[1],3))\n",
    "model_fscore.append(round(f1_score(yval,svm_pred,average = None)[1],3))\n",
    "model_fscore.append(round(f1_score(yval,rf_pred,average = None)[1],3))\n",
    "model_fscore.append(round(f1_score(yval,boost_pred,average = None)[1],3))\n",
    "\n",
    "model_precision = []\n",
    "model_precision.append(round(precision_score(yval,predict_test,average = None)[1],3))\n",
    "model_precision.append(round(precision_score(yval,pred_lreg,average = None)[1],3))\n",
    "model_precision.append(round(precision_score(yval,svm_pred,average = None)[1],3))\n",
    "model_precision.append(round(precision_score(yval,rf_pred,average = None)[1],3))\n",
    "model_precision.append(round(precision_score(yval,boost_pred,average = None)[1],3))\n",
    "\n",
    "model_recall = []\n",
    "model_recall.append(round(recall_score(yval,predict_test,average = None)[1],3))\n",
    "model_recall.append(round(recall_score(yval,pred_lreg,average = None)[1],3))\n",
    "model_recall.append(round(recall_score(yval,svm_pred,average = None)[1],3))\n",
    "model_recall.append(round(recall_score(yval,rf_pred,average = None)[1],3))\n",
    "model_recall.append(round(recall_score(yval,boost_pred,average = None)[1],3))\n",
    "\n",
    "res_list = []\n",
    "res_list.append(model_accuracy)\n",
    "res_list.append(model_fscore)\n",
    "res_list.append(model_precision)\n",
    "res_list.append(model_recall)\n",
    "\n",
    "eval_metrics_hit = ['Accuracy','F-Score','Precision','Recall']\n",
    "models_to_test_hit = ['K-Nearest Neighbors','Logistic Regression','Support Vector Machine','Random Forest','XGBoost']\n",
    "metrics_hit = pd.DataFrame(res_list, columns=models_to_test_hit, index=eval_metrics_hit)\n",
    "metrics_hit.index.name = 'Metric'\n",
    "emptydf = pd.DataFrame()\n",
    "emptydf.to_csv('results/eval_metrics_training.csv', mode='a')\n",
    "metrics_hit.to_csv('results/eval_metrics_training.csv', mode='a')\n",
    "\n",
    "print('\\nEvaluation Metrics for Genre and Hit Prediction respectively:\\n')\n",
    "os.system('column -t -s \",\" results/eval_metrics_training.csv')\n",
    "print('\\nModel Selection:\\n\\nFrom the above results, we can see that the Gradient Boosted Tree model works better for predicting \\nthe Genre and the Random Forest model works best to predict if a given song will make it to the billboard or not. \\nFurthermore, we want to see how these models perform on new data.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "### Load the Test set to see the performance of the model in predicting the correct Genre ###\n",
    "\n",
    "data_test_genre = pd.read_csv('data/data_genre_test.csv')\n",
    "ytest_genre, xtest_genre = data_test_genre['label'], data_test_genre[data_test_genre.columns[:len(data_test_genre.columns)-1]]\n",
    "\n",
    "best_model_genre = joblib.load('models/xgboost_genre_trained.pkl')\n",
    "pred_best_model_genre = best_model_genre.predict(xtest_genre)\n",
    "test_list_genre = []\n",
    "eval_metrics_genre = ['Accuracy','F-Score']\n",
    "test_list_genre.append(round(accuracy_score(ytest_genre,pred_best_model_genre),3))\n",
    "test_list_genre.append(round(f1_score(ytest_genre,pred_best_model_genre,average='weighted'),3))\n",
    "metrics_genre = pd.DataFrame(test_list_genre, columns=['XGBoost'], index=eval_metrics_genre)\n",
    "metrics_genre.index.name = 'Metric'\n",
    "metrics_genre.to_csv('results/eval_metrics_test.csv')\n",
    "\n",
    "### Load the Test set to see the performance of the model in the Hit prediction of a Song ###\n",
    "\n",
    "data_test = pd.read_csv('data/data_hit_test.csv')\n",
    "ytest, xtest = data_test['Label'], data_test.iloc[:,:-1]\n",
    "\n",
    "best_model_hit = joblib.load('models/random_forest_hit_trained.pkl')\n",
    "pred_best_model_hit = best_model_hit.predict(xtest)\n",
    "test_list_hit = []\n",
    "test_list_hit.append(round(accuracy_score(ytest,pred_best_model_hit),3))\n",
    "test_list_hit.append(round(f1_score(ytest,pred_best_model_hit,average='weighted'),3))\n",
    "test_list_hit.append(round(precision_score(ytest,pred_best_model_hit,average = None)[1],3))\n",
    "test_list_hit.append(round(recall_score(ytest,pred_best_model_hit,average = None)[1],3))\n",
    "eval_metrics_hit = ['Accuracy','F-Score','Precision','Recall']\n",
    "metrics_hit = pd.DataFrame(test_list_hit, columns=['Random Forest'], index=eval_metrics_hit)\n",
    "metrics_hit.index.name = 'Metric'\n",
    "emptydf = pd.DataFrame()\n",
    "emptydf.to_csv('results/eval_metrics_test.csv', mode='a')\n",
    "metrics_hit.to_csv('results/eval_metrics_test.csv', mode='a')\n",
    "\n",
    "print('\\nEvaluation Metrics for Genre and Hit Prediction on Test data respectively:\\n')\n",
    "os.system('column -t -s \",\" results/eval_metrics_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-c\", \"--construct\",type=str2bool, nargs='?', help=\"Extract data from sources and construct the dataset\")\n",
    "parser.add_argument(\"-t\", \"--train\",type=str2bool, nargs='?', help=\"Train the models to find the best performing one and test it on the Test data\")\n",
    "args = parser.parse_args()\n",
    "if args.construct:\n",
    "    dataset_creation = True\n",
    "else:\n",
    "    dataset_creation = False\n",
    "if args.train:\n",
    "    do_train = True\n",
    "else:\n",
    "    do_train = False\n",
    "\n",
    "if dataset_creation == True:\n",
    "    print('Dataset Construction started')\n",
    "    os.system('python3 dataset_constructor.py')\n",
    "    print('Datasets successfully constructed')\n",
    "\n",
    "if do_train == True:\n",
    "    print('Training started')\n",
    "    os.system('python3 train.py')\n",
    "\n",
    "os.system('python3 validate.py')\n",
    "\n",
    "os.system('python3 test.py')\n",
    "\n",
    "'''\n",
    "\n",
    "Datasets are stored in data/\n",
    "Models are stored in the models/ directory\n",
    "Intermediate training results are stored in conf_matrices/\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
